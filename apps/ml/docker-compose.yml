version: '3.8'

services:
  pet-health-ml-inference:
    build: .
    ports:
      - "5000:5000"
    environment:
      - INFERENCE_HOST=0.0.0.0
      - INFERENCE_PORT=5000
      - INFERENCE_DEBUG=false
    volumes:
      - ./models:/app/models:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s